os: linux
dist: jammy
services:
- docker
language: python
python:
- '3.10'
env:
  global:
  - BUCKET_NAME=backup-bucket
  - AWS_ACCESS_KEY_ID=test
  - AWS_SECRET_ACCESS_KEY=test
branches:
  only:
  - main
install:
- curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
- unzip awscliv2.zip
- sudo ./aws/install
- pip install awscli-local
jobs:
  include:
    - name: backup once
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup.yml up --detach
      - export TIME=`date "+%Y%m%dT%H%M"`
      - sleep 10
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: starting message
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup.yml up --detach
      - sleep 10
      - docker-compose --file tests/docker-compose-backup.yml logs | grep 'multiple-databases-backup is starting, backup first.'
      - docker-compose --file tests/docker-compose-backup.yml logs | grep 'multiple-databases-backup is finished, exiting.'
      - docker-compose --file tests/docker-compose-backup.yml logs
    - name: crontab
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup-minute.yml up --detach
      - sleep 1m
      - export TIME=`date "+%Y%m%dT%H%M"`
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
      - sleep 1m
      - export TIME=`date "+%Y%m%dT%H%M"`
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup once when erasing the SCHEDULE variable
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup-minute.yml run -e SCHEDULE= backup | tee backup.log
      - cat backup.log | grep 'There is not SCHEDULE variable'
    - name: exit with SCHEDULE wrong format
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup-minute.yml run -e SCHEDULE="X * *" backup || echo "Backup failed" > backup.log
      - test -f backup.log
