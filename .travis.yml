os: linux
dist: jammy
services:
- docker
language: python
python:
- '3.10'
env:
  global:
  - BUCKET_NAME=backup-bucket
  - AWS_ACCESS_KEY_ID=test
  - AWS_SECRET_ACCESS_KEY=test
branches:
  only:
  - main
install:
- curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
- unzip awscliv2.zip
- sudo ./aws/install
- pip install awscli-local
jobs:
  include:
    - name: backup once
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup.yml up --detach
      - export DATE=`date "+%Y-%m-%d"`
      - export TIME=`date "+%Y%m%dT%H%M"`
      - sleep 10
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/${DATE}/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: starting message
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup.yml up --detach
      - sleep 10
      - docker-compose --file tests/docker-compose-backup.yml logs | grep 'multiple-databases-backup is starting, backup first.'
      - docker-compose --file tests/docker-compose-backup.yml logs | grep 'multiple-databases-backup is finished, exiting.'
      - docker-compose --file tests/docker-compose-backup.yml logs
    - name: crontab
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup-minute.yml up --detach
      - sleep 1m
      - export DATE=`date "+%Y-%m-%d"`
      - export TIME=`date "+%Y%m%dT%H%M"`
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/${DATE}/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
      - sleep 1m
      - export DATE=`date "+%Y-%m-%d"`
      - export TIME=`date "+%Y%m%dT%H%M"`
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/${DATE}/postgres15_postgres_1_${TIME}.sql.gz" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup once when erasing the SCHEDULE variable
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - docker-compose --file tests/docker-compose-backup-minute.yml run -e SCHEDULE= backup | tee backup.log
      - cat backup.log | grep 'There is not SCHEDULE variable'
    - name: exit with SCHEDULE wrong format
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-minute.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - (docker-compose --file tests/docker-compose-backup-minute.yml run -e SCHEDULE="0 * *" backup > backup.log) || (echo "The exit code is $?." | tee error.log)
      - cat backup.log
      - cat backup.log | grep 'The SCHEDULE variable should contain five fields exactly.'
      - cat error.log | grep 'The exit code is 1.'
    - name: GPG encrypt with asymmetric key
      env:
      - GPG_PRIVATE_KEY_PATH=tests/gpg-key/ithuan.tw.asc
      - GPG_PRIVATE_KEY_PASSPHRASE_PATH=tests/gpg-key/ithuan.tw.passphrase
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-encrypt.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - gpg --import --batch ${GPG_PRIVATE_KEY_PATH}
      - GPG_PUBLIC_KEY=`gpg --armor --export ithuan+multiple-databases-backup@ithuan.tw | base64 --wrap 0`
      - echo "GPG_PUBLIC_KEY=${GPG_PUBLIC_KEY}" | tee tests/.env
      - docker-compose --file tests/docker-compose-backup-encrypt.yml run --rm backup
      - export DATE=`date "+%Y-%m-%d"`
      - export TIME=`date "+%Y%m%dT%H%M"`
      - sleep 10
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "postgres15_postgres_1/${DATE}/postgres15_postgres_1_${TIME}.sql.gz.gpg" postgres15.sql.gz.gpg
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
      - gpg --decrypt --batch --pinentry-mode loopback --passphrase-file ${GPG_PRIVATE_KEY_PASSPHRASE_PATH} postgres15.sql.gz.gpg | zcat
    - name: backup strategy for keeping backup in 72 hours(3 days)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2023-08-27/postgres15_postgres_1_20230827T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for deleting backup exceeding 72 hours(3 days)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2023-08-27/postgres15_postgres_1_20230827T0900.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz || (echo 'Not found.' | tee error.log)
      - cat error.log | grep 'Not found.'
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"

    - name: backup strategy for keeping day backup in 90 days(3 months)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2023-06-01/postgres15_postgres_1_20230601T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for keeping day backups if they are backuped in different day.
      env:
      - NOW='2023-08-30 9:00'
      - DAY1_BACKUP="postgres15_postgres_1/2023-06-01/postgres15_postgres_1_20230601T1000.sql.gz"
      - DAY2_BACKUP="postgres15_postgres_1/2023-06-02/postgres15_postgres_1_20230602T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${DAY1_BACKUP}" test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${DAY2_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${DAY1_BACKUP}" postgres15-1.sql.gz
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${DAY2_BACKUP}" postgres15-2.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for deleting backup because of keeping day backup only
      env:
      - NOW='2023-08-30 9:00'
      - DAY_BACKUP="postgres15_postgres_1/2023-06-01/postgres15_postgres_1_20230601T0900.sql.gz"
      - NOT_DAY_BACKUP="postgres15_postgres_1/2023-06-01/postgres15_postgres_1_20230601T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${DAY_BACKUP}" test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${NOT_DAY_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${NOT_DAY_BACKUP}" postgres15.sql.gz || (echo 'Not found.' | tee error.log)
      - cat error.log | grep 'Not found.'
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for deleting day backup exceeding 90 days(3 months)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2023-05-01/postgres15_postgres_1_20230501T0900.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz || (echo 'Not found.' | tee error.log)
      - cat error.log | grep 'Not found.'
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for keeping month backup in 36 months(3 years)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2020-08-01/postgres15_postgres_1_20200801T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for keeping month backups if they are backuped in different month.
      env:
      - NOW='2023-08-30 9:00'
      - MONTH1_BACKUP="postgres15_postgres_1/2022-01-01/postgres15_postgres_1_20220101T1000.sql.gz"
      - MONTH2_BACKUP="postgres15_postgres_1/2022-02-02/postgres15_postgres_1_20220202T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${MONTH1_BACKUP}" test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${MONTH2_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${MONTH1_BACKUP}" postgres15-1.sql.gz
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${MONTH2_BACKUP}" postgres15-2.sql.gz
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for deleting backup because of keeping month backup only
      env:
      - NOW='2023-08-30 9:00'
      - MONTH_BACKUP="postgres15_postgres_1/2023-06-01/postgres15_postgres_1_20230601T0900.sql.gz"
      - NOT_MONTH_BACKUP="postgres15_postgres_1/2023-06-20/postgres15_postgres_1_20230620T1000.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${MONTH_BACKUP}" test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${NOT_MONTH_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${NOT_MONTH_BACKUP}" postgres15.sql.gz || (echo 'Not found.' | tee error.log)
      - cat error.log | grep 'Not found.'
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
    - name: backup strategy for deleting month backup exceeding 36 months(3 years)
      env:
      - NOW='2023-08-30 9:00'
      - OLD_BACKUP="postgres15_postgres_1/2020-07-01/postgres15_postgres_1_20200701T0900.sql.gz"
      before_script:
      - docker-compose --file tests/postgres15/docker-compose.yml up --detach
      - docker-compose --file tests/s3/docker-compose-localstack.yml up --detach
      - docker-compose --file tests/docker-compose-backup-strategy.yml build
      - sleep 10
      - awslocal s3api create-bucket --bucket "${BUCKET_NAME}"
      script:
      - sudo date --set "${NOW}"
      - echo '# SQL' | gzip > test.sql.gz
      - awslocal s3api put-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" test.sql.gz
      - docker-compose --file tests/docker-compose-backup.yml run --rm backup
      - awslocal s3api get-object --bucket "${BUCKET_NAME}" --key "${OLD_BACKUP}" postgres15.sql.gz || (echo 'Not found.' | tee error.log)
      - cat error.log | grep 'Not found.'
      - awslocal s3api list-objects --bucket "${BUCKET_NAME}"
